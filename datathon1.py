# -*- coding: utf-8 -*-
"""Datathon1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TKOqX6tJsIHCscbYJ-8sEJE5akG-KBUV
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import load_model, Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
import seaborn as sns

"""import data

"""

solar_data = pd.read_csv('solar_sensor_data.csv')
solar_data

sdata = solar_data[20::21]
sdata

weather_data = pd.read_csv('weather_sensor_data.csv')
weather_data

"""Merge two datasets"""

df = pd.merge(sdata, weather_data, on=['LOCATION','DATE_TIME'],how = 'inner')
df.head()

df.shape

"""Following code is added finally for Mongo DB part

"""

from pickle import TRUE
df.to_csv("merge_dataset.csv", index=TRUE)
print("merge data set saved to 'merge_dataset.csv'")

"""indexing the "DATE_TIME" as the index and drop the "DATE_TIME" column"""

df.index = pd.to_datetime(df['DATE_TIME'], format='%m/%d/%Y %H:%M', dayfirst=False)
df.drop('DATE_TIME',axis=1,inplace=True)
df.head()

df.shape

df.info()

df.isnull().sum()

duplicates = df.duplicated().sum()
duplicates

"""#EDA part"""

df.describe().T

df.describe(include ="object")

from google.colab import drive
drive.mount('/content/drive')

"""Lets plot histogram to understand the distribution of data"""

for i in df.select_dtypes(include="number").columns:
    sns.histplot(data=df,x=i)
    plt.show()

"""Lets IDentify the outlier using boxplot"""

for i in df.select_dtypes(include="number").columns:
    sns.boxplot(data=df,x=i)
    plt.show()

"""Lets find the corelation of each features

"""

df.select_dtypes(include="number").corr()

"""Lets use heat map to understand the correlation more"""

plt.figure(figsize=(10,10))
sns.heatmap(df.select_dtypes(include="number").corr(), annot= True)

#Remove categorical
Sfeatures = ["DC_POWER","AC_POWER", "DAILY_YIELD", "TOTAL_YIELD", "AMBIENT_TEMPERATURE","MODULE_TEMPERATURE", "IRRADIATION"]
data_features = df[Sfeatures]

from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import MinMaxScaler

"""Using LSTM for Model building"""

# Normalizing the data
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data_features)


train_size = int(len(data_scaled) * 0.8)  # 80% for training
train_data = data_scaled[:train_size]
test_data = data_scaled[train_size:]

# Prepare data for LSTM
sequence_length = 50
X = []
for i in range(sequence_length, len(data_scaled)):
    X.append(data_scaled[i-sequence_length:i])
X = np.array(X)


def prepare_sequences(data):
    X = []
    for i in range(sequence_length, len(data)):
        X.append(data[i-sequence_length:i])
    return np.array(X)


X_train = prepare_sequences(train_data)
X_test = prepare_sequences(test_data)

# Build LSTM model
model = tf.keras.Sequential([
    tf.keras.layers.LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),
    tf.keras.layers.LSTM(32, return_sequences=False),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(X_train.shape[2], activation='linear')
])
model.compile(optimizer='adam', loss='mse')

# Training the model
model.fit(X_train, train_data[sequence_length:], epochs=10, batch_size=32, validation_split=0.1)

# Predict reconstruction errors
X_test_pred = model.predict(X_test)
reconstruction_errors = np.mean(np.abs(X_test_pred - test_data[sequence_length:]), axis=1)

# Determine anomalies based on a threshold
threshold = np.percentile(reconstruction_errors, 95)
anomalies = reconstruction_errors > threshold


df['anomaly_lstm'] = 0
df.iloc[train_size + sequence_length:, df.columns.get_loc('anomaly_lstm')] = anomalies.astype(int)

"""Visualizing anomalies"""

#plot for DC_POWER
plt.figure(figsize=(12, 6))
plt.plot(df.index, df['DC_POWER'], label='DC_POWER', color='yellow')
anomalies = df[df['anomaly_lstm'] == 1]
plt.scatter(anomalies.index, anomalies['DC_POWER'], color='red', label='Anomalies')
# Plot for IRRADIATION
plt.plot(df.index, df['IRRADIATION'], label='IRRADIATION', color='green', alpha=0.9)
irr_anomalies = df[df['anomaly_lstm'] == 1]
plt.scatter(irr_anomalies.index, irr_anomalies['IRRADIATION'], color='black', label='IRRADIATION Anomalies')

# Plot for MODULE_TEMPERATURE
plt.plot(df.index, df['MODULE_TEMPERATURE'], label='IRRADIATION', color='blue', alpha=0.9)
MTemp_anomalies = df[df['anomaly_lstm'] == 1]
plt.scatter(MTemp_anomalies.index, MTemp_anomalies['MODULE_TEMPERATURE'], color='Orange', label='MODULE_TEMPERATURE Anomalies')

plt.title("Combined Anomaly Visualization")
plt.xlabel("Date Time")
plt.ylabel("Values")
plt.legend()
plt.show()

df.to_csv("anomaly_results.csv", index=TRUE)
print("Anomaly detection results saved to 'anomaly_results.csv'")

!pip install apache-airflow

from airflow.models import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

